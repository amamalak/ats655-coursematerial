{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your own EOF code\n",
    "#### by Elizabeth Barnes\n",
    "\n",
    "Demonstration of how to code up EOF analysis from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#.............................................\n",
    "# IMPORT STATEMENTS\n",
    "#.............................................\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import scipy.stats as stats\n",
    "import numpy.linalg as LA\n",
    "import scipy.io as sio\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import general_functions as gf\n",
    "importlib.reload(gf)\n",
    "gf.add_parent_dir_to_path()\n",
    "\n",
    "from lib import class_general_functions as cgf\n",
    "importlib.reload(cgf)\n",
    "\n",
    "#.............................................\n",
    "# PLOTTING COMMANDS\n",
    "#.............................................\n",
    "gf.cc()\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a place for user input. Which EOF do you want to plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "# which EOF do you want to plot?\n",
    "eof_num = 1\n",
    "#-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "This data is composed of 7 weather variables averaged over one year for each state in the US (thus, 50 states). There is also an option to comment this out and instead use a matrix of random data (just for comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the different variables for each state\n",
    "descriptor_names = ['temp','precip','% sun','sun hours','clear dys','humid AM','humid PM']\n",
    "\n",
    "# load the data\n",
    "DATA = sio.loadmat('data/state_data_raw.mat')\n",
    "Y = DATA['X']\n",
    "\n",
    "# UNCOMMENT if you want to use RANDOM data\n",
    "# Y = np.random.rand(np.size(Y,axis=0),np.size(Y,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process your data into anomalies and decide whether to standardize or not\n",
    "\n",
    "One decision you need to make is whether you wish to standardize your data. In this example, the 7 weather variables all have very different units. Thus, if you don't standardize your data the variable with the largest units will likely dominate the EOF calculation - and this is obviously not what we want. So, I standardize. However, note you can uncomment one of the lines if you want to see what happens when you do not standardize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate anomalies from the state-mean (sample-mean) - call this \"X\"\n",
    "Ymean = np.nanmean(Y,axis = 0)\n",
    "X = Y - Ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any NaNs\n",
    "#i = np.isnan(X)\n",
    "#X[i] = 0.   #this step does not make a lot of sense setting them to zero...\n",
    "            #should be more careful with this and calculate covariance to not...\n",
    "            #include NaNs (there are 5 in this data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the data - call it \"Xw\"\n",
    "Xstd = np.nanstd(X,axis = 0)\n",
    "Xw = X/Xstd\n",
    "\n",
    "# UNCOMMENT if you don't want to standardize the data\n",
    "#Xw = X;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate EOF using temporal covariance matrix (covariance along the sampling dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.54408661         nan         nan  0.37458539  0.21872046\n",
      "  -0.10306989]\n",
      " [ 0.54408661  1.                 nan         nan -0.39337431  0.64439514\n",
      "   0.5403986 ]\n",
      " [        nan         nan         nan         nan         nan         nan\n",
      "          nan]\n",
      " [        nan         nan         nan         nan         nan         nan\n",
      "          nan]\n",
      " [ 0.37458539 -0.39337431         nan         nan  1.         -0.52428887\n",
      "  -0.77892432]\n",
      " [ 0.21872046  0.64439514         nan         nan -0.52428887  1.\n",
      "   0.7324305 ]\n",
      " [-0.10306989  0.5403986          nan         nan -0.77892432  0.7324305\n",
      "   1.        ]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-506c5de5b2a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# calculate eigenvalues and eigenvectors of C; lam should be 7x1, E should be 7x7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# sort eigenvalues and vector by the largest to smallest eigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36meig\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m     \u001b[0m_assertFinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assertFinite\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Array must not contain infs or NaNs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_isEmpty2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# calculate the temporal covariance matrix, dimensions should be [7 x 7]\n",
    "C = 1./np.size(Xw,axis = 0)*np.dot(np.transpose(Xw),Xw) # need to recode this to allow for NaNs\n",
    "\n",
    "print(C)\n",
    "\n",
    "# calculate eigenvalues and eigenvectors of C; lam should be 7x1, E should be 7x7\n",
    "lam, E = LA.eig(C) \n",
    "\n",
    "# sort eigenvalues and vector by the largest to smallest eigenvalues\n",
    "i = np.flipud(np.argsort(lam))\n",
    "lam = lam[i]\n",
    "E = E[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert eigenvalues to percent variance explained\n",
    "pve = 100.*lam/np.sum(lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PC timeseries and scaled EOF (called \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take only one eigenvector, user specified by \"eof_num\" above\n",
    "e1 = E[:,eof_num-1] #e1 should be 7x1 or 1x7 depending on your software\n",
    "\n",
    "# calculate the the PC associated with the EOF of interest\n",
    "z1 = np.dot(Xw,e1) #z1 should be 50x1 or 1x50 depending on your software\n",
    "\n",
    "# standardize z1\n",
    "z1 = (z1-np.mean(z1))/np.std(z1)\n",
    "\n",
    "# calculate d1 for plotting in physical units, not standardized/weighted units,\n",
    "# thus it uses the original \"X\" anomaly data\n",
    "d1 = (1./np.size(X,axis=0))*np.dot(np.transpose(z1),X)\n",
    "\n",
    "# calculate d1 for plotting in standardized/weighted units,\n",
    "# thus it uses the \"Xw\" anomaly data\n",
    "d1s = (1./np.size(Xw, axis = 0))*np.dot(np.transpose(z1),Xw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results: eigenvalue spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgf.cfig(1)\n",
    "plt.plot(np.arange(1,np.size(pve)+1.),pve,'o-',linewidth = 2, color = 'black')\n",
    "\n",
    "plt.xlim(0.5, 7.5)\n",
    "plt.xlabel('eigenvalue position')\n",
    "plt.ylabel('percent variance explained (%)')\n",
    "\n",
    "# plot error bars according to North et al.abs\n",
    "# here we will assume that all of the data is independent (is that a good assumption?)\n",
    "# such that Nstar = N\n",
    "Nstar = np.size(X,axis = 0)\n",
    "eb = pve*np.sqrt(2./Nstar)\n",
    "plt.errorbar(np.arange(1,np.size(pve)+1.),pve,yerr = eb/2, xerr = None, linewidth = 1, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results: EOF in standardized units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgf.cfig(2)\n",
    "plt.plot(d1s,'s-k',linewidth = 2, label = 'd1s')\n",
    "plt.plot(e1,'s-r',linewidth = 2, label = 'e1')\n",
    "\n",
    "plt.xticks(np.arange(len(descriptor_names)),descriptor_names, fontsize = 7)\n",
    "plt.xlim(-0.5, 6.5)\n",
    "\n",
    "plt.legend()\n",
    "gf.plot_zero_lines()\n",
    "plt.ylabel('sigma')\n",
    "plt.title('d standardized')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results: EOF in physical units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgf.cfig(3)\n",
    "plt.plot(d1,'s-k',linewidth = 2, label = 'd1')\n",
    "\n",
    "plt.xticks(np.arange(len(descriptor_names)),descriptor_names, fontsize = 7)\n",
    "gf.plot_zero_lines()\n",
    "plt.legend()\n",
    "plt.ylabel('physical units')\n",
    "plt.title('d in physical units')\n",
    "plt.xlim(-0.5, 6.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results: PC as a U.S. map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgf.cfig(4, fig_width = cgf.fig_width*1.5, fig_height = cgf.fig_height*1.5)\n",
    "\n",
    "# create the map\n",
    "m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "        projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "\n",
    "# load the shapefile, use the name 'states'\n",
    "m.readshapefile('data/st99_d00', name='states', drawbounds=True)\n",
    "\n",
    "# collect the state names from the shapefile attributes so we can\n",
    "# look up the shape obect for a state by it's name\n",
    "state_names = []\n",
    "for shape_dict in m.states_info:\n",
    "    state_names.append(shape_dict['NAME'])\n",
    "\n",
    "state_names_list = sorted(list(set(state_names)))\n",
    "state_names_list.pop(state_names_list.index('District of Columbia'))\n",
    "state_names_list.pop(state_names_list.index('Puerto Rico'))\n",
    "\n",
    "ax = plt.gca() # get current axes instance\n",
    "\n",
    "colors={}\n",
    "cmap = plt.cm.get_cmap('seismic')\n",
    "vmin = -3.\n",
    "vmax = 3.\n",
    "\n",
    "for shapedict in m.states_info:\n",
    "    statename = shapedict['NAME']\n",
    "    # skip DC and Puerto Rico.\n",
    "    if statename not in ['District of Columbia','Puerto Rico']:\n",
    "        z = z1[state_names_list.index(statename)]\n",
    "        # calling colormap with value between 0 and 1 returns\n",
    "        # rgba value.  Invert color range (hot colors are high\n",
    "        # population), take sqrt root to spread out colors more.\n",
    "        colors[statename] = cmap((z-vmin)/(vmax-vmin))[:3]\n",
    "\n",
    "for nshape,seg in enumerate(m.states):\n",
    "    # skip DC and Puerto Rico.\n",
    "    if state_names[nshape] not in ['District of Columbia','Puerto Rico', 'Alaska', 'Hawaii']:\n",
    "        color = colors[state_names[nshape]]\n",
    "        \n",
    "        poly = Polygon(seg,facecolor=color,edgecolor=color)\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "        \n",
    "plt.title('PC' + str(eof_num) + ' value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These PC values show how much a given state \"looks\" like the EOF structure above. Dark blue and dark red denote large opposite signed values (remember, the sign itself doesn't matter here - just the relationships between values/signs across states)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
